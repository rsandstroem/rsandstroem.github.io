<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <title>Data Scientist Blog</title>
        <link rel="stylesheet" href="https://rsandstroem.github.io/theme/css/main.css" />
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <script>
            (adsbygoogle = window.adsbygoogle || []).push({
                google_ad_client: "ca-pub-5699621187774656",
                enable_page_level_ads: true
            });
        </script>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <script>
            (adsbygoogle = window.adsbygoogle || []).push({
                google_ad_client: "ca-pub-5699621187774656",
                enable_page_level_ads: true
            });
        </script>
        <link rel='stylesheet' href='https://cdn.pydata.org/bokeh/release/bokeh-0.12.6.min.css' type="text/css">
        <script src="https://cdn.pydata.org/bokeh/release/bokeh-0.12.6.min.js" type="text/javascript"></script>
        <script type="text/javascript">
            Bokeh.set_log_level("info");
        </script>
        <!--[if IE]>
            <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->

</head>

<body id="index" class="home">
<a href="https://github.com/rsandstroem/">
<img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub" />
</a>
        <header id="banner" class="body">
                <h1><a href="https://rsandstroem.github.io/">Data Scientist Blog </a></h1>
                <nav><ul>
    
                        <li><a href="https://rsandstroem.github.io/pages/about.html">about</a></li>
                    <li><a href="https://rsandstroem.github.io/category/posts.html">posts</a></li>
                </ul>
                </nav>
        </header><!-- /#banner -->


            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="https://rsandstroem.github.io/serverlessPredictionService.html">Hosting a machine learning prediction service on serverless infrastructure</a></h1>
<footer class="post-info">
        <span>Don 04 Januar 2018</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/aws.html">aws</a><a href="https://rsandstroem.github.io/tag/azure.html">azure</a><a href="https://rsandstroem.github.io/tag/machine-learning.html">machine learning</a><a href="https://rsandstroem.github.io/tag/serverless.html">serverless</a><a href="https://rsandstroem.github.io/tag/lambda.html">lambda</a><a href="https://rsandstroem.github.io/tag/python.html">python</a><a href="https://rsandstroem.github.io/tag/flask.html">flask</a><a href="https://rsandstroem.github.io/tag/tutorial.html">tutorial</a></span>
</footer><!-- /.post-info --><h1>Background</h1>
<p>I was asked to administrate all users and resources of my employer's Amazon Web Services (<a href="https://aws.amazon.com/">AWS</a>) a few months ago. To demonstrate that I have the appropriate training to take on this role, an AWS Certified Solutions Architect diploma was required. During my online course with <a href="https://acloud.guru/">A Cloud Guru</a> I learned about serverless architectures. After passing the certification exam, I decided to experiment with serverless architecture to determine if they can help me out in my daily work as a data scientist. I am happy to share my experience with you below.</p>
<h1>Introduction</h1>
<p>This post shows how to host machine learning prediction services on the cloud with infinite scaling, zero downtime, zero maintenance, at a very low cost. By using serverless cloud services it is possible to create end to end solutions for data science projects and enable end-users to consume the insights over the Internet.</p>
<p><img alt="Data Science Life Cycle" width="48%" src="/images/datasciencelifecycle.png" align="right"/>
First let us back up a bit and set the stage. The data science life cycle involves </p>
<ul>
<li>understanding the business, </li>
<li>acquire, understand and prepare the data</li>
<li>train a machine learning model on the data</li>
<li>validate the model and estimate uncertainties</li>
<li>deploy a prediction service based on the model</li>
</ul>
<p>The first steps of this life cycle are typically done on-premise with local tools and resources. However, at some point the users need to access the prediction service that you prepared. They cannot all connect to you laptop to consume the insights provided by your new service. A common solution is to deploy the prediction service as an API, which can be accessible only to enterprise users, or be open to anyone on the Internet depending on the project requirements.</p>
<p><a href="https://studio.azureml.net/">Azure Machine Learning</a> makes creation of an API really easy. Once your model is trained and validated, it is just a few clicks in the graphical interface and you are ready to integrate the new prediction service with web apps or Microsoft Office. </p>
<p>A downside to Azure Machine Learning is that the data used in the training is exposed to the Internet. For many companies this is a red flag. Either regulations prevent sensitive data from leaving enterprise data centres, or the risk appetite of the business is a significant hurdle.</p>
<p>But what if you could keep all enterprise confidential data on the corporate network, and only host the prediction service with a web interface? The only data being exposed to the cloud provider is the data that the user sends as input to the prediction service.</p>
<p>Serverless architectures provide infinite scaling, zero downtime, zero maintenance, at a very low cost. Serverless architectures have revolutionized the way we think of hosting services since its introduction in 2014, so I am going to show how to host a machine learning prediction service on AWS Lambda in addition to hosting it on the local corporate network. </p>
<h1>Training the classifier</h1>
<p>In the data science community <a href="http://scikit-learn.org/stable/">scikit-learn</a> is a very popular choice for traditional machine learning. To demonstrate how you can host a scikit-learn model as a prediction service on serverless infrastructure we must first create and train a scikit-learn model. </p>
<p>The example below pulls in thousands of newsgroup messages and builds a model that can detect if the topic of the discussion is guns and firearms.</p>
<div class="highlight"><pre><span></span><span class="c1"># coding: utf-8</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="kn">import</span> <span class="n">joblib</span>

<span class="n">twenty_train</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> 
                                  <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                                  <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">twenty_test</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> 
                                 <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                                 <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># create a list of 0 for negative labels and 1 for positive labels</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="mi">16</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">twenty_train</span><span class="o">.</span><span class="n">target</span><span class="p">]</span> 
<span class="n">y_val</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="mi">16</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">twenty_test</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>

<span class="c1"># train the preprocessing of the data</span>
<span class="n">preproc</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">preproc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">twenty_train</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">preproc</span><span class="p">,</span> <span class="s1">&#39;preproc_cvtfidf.pkl&#39;</span><span class="p">)</span>

<span class="c1"># preprocess the data</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">preproc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">twenty_train</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">X_val</span> <span class="o">=</span> <span class="n">preproc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">twenty_test</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># train the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;log&#39;</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="s1">&#39;clf_sdg.pkl&#39;</span><span class="p">)</span>
</pre></div>


<p>In a real world scenario you should spend time on validating the model, quantify sampling bias, propagate uncertainties etc, but for this tutorial the simple script above is fit for purpose.</p>
<p><em>This model is a very basic logistic regression implemented with stochastic gradient decent and TF-IDF preprocessing. Give me a shout in the comments section below if you want to see a more sophisticated text classification in another blog post.</em></p>
<p>The preprocessing and the classifier are persistified as local files. We need those to set up an independent prediction service.</p>
<h1>Setting up a prediction service</h1>
<h2>Testing basic prediction locally</h2>
<p>Before publishing your new gun detection model to the world you should make sure it works as intended. Simply load the model files and send some random text messages through the model.</p>
<div class="highlight"><pre><span></span><span class="c1"># coding: utf-8</span>
<span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="kn">import</span> <span class="n">joblib</span>
<span class="n">pre</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;preproc_cvtfidf.pkl&#39;</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;clf_sdg.pkl&#39;</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;I shot the sheriff.&quot;</span><span class="p">,</span> <span class="s2">&quot;School shooting in Las Vegas. Gunman killed by police.&quot;</span><span class="p">,</span> <span class="s2">&quot;Prime minister struggles to settle Brexit deal.&quot;</span><span class="p">]</span> 
<span class="n">X</span> <span class="o">=</span> <span class="n">pre</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)[:],</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span> <span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">output</span><span class="p">))</span>
</pre></div>


<p>Output should look like this if all is well:</p>
<div class="highlight"><pre><span></span><span class="o">[(</span><span class="s1">&#39;I shot the sheriff.&#39;</span>, <span class="m">0</span>, <span class="m">0</span>.33693677715786069<span class="o">)</span>, 
<span class="o">(</span><span class="s1">&#39;School shooting in Las Vegas. Gunman killed by police.&#39;</span>, <span class="m">1</span>, <span class="m">0</span>.5571287620731008<span class="o">)</span>, 
<span class="o">(</span><span class="s1">&#39;Prime minister struggles to settle Brexit deal.&#39;</span>, <span class="m">0</span>, <span class="m">0</span>.10020190594453801<span class="o">)]</span>
</pre></div>


<p>The output shows that the model works as intended; messages are scored higher if they contain words that suggest that the topic is firearms.</p>
<h2>Local webservice</h2>
<p>In preparation of hosting the prediction service on the cloud we copy the two model files to an S3 bucket. Using <a href="https://aws.amazon.com/cli/">AWS Command Line Interface</a> :</p>
<div class="highlight"><pre><span></span>aws s3 cp clf_sdg.pkl s3://yourbucketname
aws s3 cp preproc_cvtfidf.pkl s3://yourbucketname
</pre></div>


<p>You can of course upload the files using the AWS console, or some alternative method.</p>
<p>Next you need to set up a virtual environment to ensure that all dependencies are available once you move the service into a Lambda function.</p>
<div class="highlight"><pre><span></span>mkdir lambda
<span class="nb">cd</span> lambda/
pip install virtualenv
virtualenv lambda_demo
<span class="nb">source</span> lambda_demo/bin/activate
pip install scikit-learn flask boto numpy scipy zappa
</pre></div>


<p>We will get to Zappa later, but at the moment of writing there is a problem with one of Zappa's dependencies, so we need to forcefully install an older version.</p>
<div class="highlight"><pre><span></span>pip install <span class="nv">toml</span><span class="o">==</span><span class="m">0</span>.9.2 --force-reinstall
</pre></div>


<p>The prediction service is going to be provided as an API written in <a href="http://flask.pocoo.org/">Flask</a> where both input and output formats will be JSON. Below is the code for my example Flask app, saved as <code>prediction_lambda.py</code>.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="kn">import</span> <span class="n">joblib</span>
<span class="kn">import</span> <span class="nn">boto</span>
<span class="kn">from</span> <span class="nn">boto.s3.key</span> <span class="kn">import</span> <span class="n">Key</span>
<span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">Flask</span>
<span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">request</span>
<span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">json</span>

<span class="n">BUCKET_NAME</span> <span class="o">=</span> <span class="s1">&#39;yourbucketname&#39;</span>
<span class="n">PREP_FILE_NAME</span> <span class="o">=</span> <span class="s1">&#39;preproc_cvtfidf.pkl&#39;</span>
<span class="n">PREP_LOCAL_PATH</span> <span class="o">=</span> <span class="n">PREP_FILE_NAME</span>
<span class="n">MODEL_FILE_NAME</span> <span class="o">=</span> <span class="s1">&#39;clf_sdg.pkl&#39;</span>
<span class="n">MODEL_LOCAL_PATH</span> <span class="o">=</span> <span class="n">MODEL_FILE_NAME</span>
<span class="n">AWS_S3_HOST</span> <span class="o">=</span> <span class="s1">&#39;s3.eu-central-1.amazonaws.com&#39;</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">Flask</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="nd">@app.route</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;POST&#39;</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">index</span><span class="p">():</span>
    <span class="c1"># retrieve message as json, should contain a payload</span>
    <span class="n">inMessage</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="n">inMessage</span><span class="p">[</span><span class="sa">u</span><span class="s1">&#39;payload&#39;</span><span class="p">]</span>
    <span class="c1"># assign score to documents in the payload</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">payload</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">prediction</span>


<span class="k">def</span> <span class="nf">load_preprocess</span><span class="p">():</span>
    <span class="c1"># read the preprocessing from a S3 bucket</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">boto</span><span class="o">.</span><span class="n">connect_s3</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="n">AWS_S3_HOST</span><span class="p">)</span>
    <span class="n">bucket</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">get_bucket</span><span class="p">(</span><span class="n">BUCKET_NAME</span><span class="p">)</span>
    <span class="n">key_obj</span> <span class="o">=</span> <span class="n">Key</span><span class="p">(</span><span class="n">bucket</span><span class="p">)</span>
    <span class="n">key_obj</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">PREP_FILE_NAME</span>
    <span class="n">contents</span> <span class="o">=</span> <span class="n">key_obj</span><span class="o">.</span><span class="n">get_contents_to_filename</span><span class="p">(</span><span class="n">PREP_LOCAL_PATH</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PREP_LOCAL_PATH</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">load_model</span><span class="p">():</span>
    <span class="c1"># read the machine learning model from a S3 bucket</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">boto</span><span class="o">.</span><span class="n">connect_s3</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="n">AWS_S3_HOST</span><span class="p">)</span>
    <span class="n">bucket</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">get_bucket</span><span class="p">(</span><span class="n">BUCKET_NAME</span><span class="p">)</span>
    <span class="n">key_obj</span> <span class="o">=</span> <span class="n">Key</span><span class="p">(</span><span class="n">bucket</span><span class="p">)</span>
    <span class="n">key_obj</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">MODEL_FILE_NAME</span>
    <span class="n">contents</span> <span class="o">=</span> <span class="n">key_obj</span><span class="o">.</span><span class="n">get_contents_to_filename</span><span class="p">(</span><span class="n">MODEL_LOCAL_PATH</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">MODEL_LOCAL_PATH</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="c1"># Preprocess the data</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">load_preprocess</span><span class="p">()</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="c1"># Create a dictionary containing input and scores</span>
    <span class="n">output</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">load_model</span><span class="p">()</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="c1"># listen on all IPs</span>
    <span class="n">app</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s1">&#39;0.0.0.0&#39;</span><span class="p">)</span>
</pre></div>


<p>To read the model files that you uploaded to the S3 bucket, app needs to have access to the bucket, so read permission should be set, and credential are needed. The AWS credentials can be saved in <code>~/.aws/config</code>. In my case, I created a <em>role</em> for my EC2 instance used for development which allows it to read and write to S3. (It goes without saying that if you do not indent to host the service on the cloud you could use local file paths instead of configuring AWS permissions.)</p>
<p>To host the Flask app on your local machine simply use</p>
<div class="highlight"><pre><span></span>python prediction_lambda.py
</pre></div>


<p>and the service will be reachable on port 5000 of localhost. To test if the service is working send it a JSON payload as POST:</p>
<div class="highlight"><pre><span></span>curl -X POST -H <span class="s2">&quot;Content-Type: application/json&quot;</span> -d <span class="s1">&#39;{&quot;payload&quot;: [&quot;I shot the sheriff&quot;,&quot;But I did not shot the deputy&quot;]}&#39;</span> localhost:5000
</pre></div>


<p>If you only want to host your gun detection service on the corporate network you are done now, congratulations! In the following section we are going to deploy it as a serverless service.</p>
<h2>Deploy to AWS Lambda</h2>
<p>AWS Lambda let's you write code and AWS magically makes sure that the code works and scales with changing load. In theory. In reality Lambda is completely clueless of what scikit-learn is, and the same goes for any other packages you might be using in your code. </p>
<p>Enter <a href="https://github.com/Miserlou/Zappa">Zappa</a>. What Zappa does is take care of all the configuration of the Lambda function and the API Gateway, so you can get your local Flask app hosted as a Lambda function with minimal effort.</p>
<p>From the folder where you saved <code>prediction_lambda.py</code>, initialize Zappa:</p>
<div class="highlight"><pre><span></span>zappa init
</pre></div>


<p>Once you have answered the questions you should have a file called <code>zappa_settings.json</code> in the local folder. Since your machine learning environment is most likely exceeding the Lambda size limit, you need to manually add <code>"slim_handler": true</code> to <code>zappa_settings.json</code>.</p>
<div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;dev&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;app_function&quot;</span><span class="p">:</span> <span class="s2">&quot;prediction_lambda.app&quot;</span><span class="p">,</span>
        <span class="nt">&quot;aws_region&quot;</span><span class="p">:</span> <span class="s2">&quot;eu-central-1&quot;</span><span class="p">,</span>
        <span class="nt">&quot;profile_name&quot;</span><span class="p">:</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
        <span class="nt">&quot;project_name&quot;</span><span class="p">:</span> <span class="s2">&quot;lambda&quot;</span><span class="p">,</span>
        <span class="nt">&quot;runtime&quot;</span><span class="p">:</span> <span class="s2">&quot;python3.6&quot;</span><span class="p">,</span>
        <span class="nt">&quot;s3_bucket&quot;</span><span class="p">:</span> <span class="s2">&quot;yourbucketname&quot;</span><span class="p">,</span>
        <span class="nt">&quot;slim_handler&quot;</span><span class="p">:</span> <span class="kc">true</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>


<p>To deploy, and later update the deployed Lambda function, simply type</p>
<div class="highlight"><pre><span></span>zappa deploy dev
zappa update dev
</pre></div>


<p>respectively. To see more information of the Lambda function the <code>status</code> command is very handy. </p>
<div class="highlight"><pre><span></span><span class="o">(</span>lambda_demo<span class="o">)</span> ubuntu@ec2devbox:~/PredictLambdaDemo/lambda$ zappa status
<span class="o">(</span>toml <span class="m">0</span>.9.2 <span class="o">(</span>/home/ubuntu/PredictLambdaDemo/lambda/lambda_demo/lib/python3.6/site-packages<span class="o">)</span>, Requirement.parse<span class="o">(</span><span class="s1">&#39;toml&gt;=0.9.3&#39;</span><span class="o">)</span>, <span class="o">{</span><span class="s1">&#39;zappa&#39;</span><span class="o">})</span>
Status <span class="k">for</span> lambda-dev: 
    Lambda Versions:      <span class="m">3</span>
    Lambda Name:          lambda-dev
    Lambda ARN:           arn:aws:lambda:eu-central-1:070741064749:function:lambda-dev
    Lambda Role ARN:      arn:aws:iam::070741064749:role/lambda-dev-ZappaLambdaExecutionRole
    Lambda Handler:       handler.lambda_handler
    Lambda Code Size:     <span class="m">10336816</span>
    Lambda Version:       <span class="nv">$LATEST</span>
    Lambda Last Modified: <span class="m">2017</span>-12-08T13:59:41.904+0000
    Lambda Memory Size:   <span class="m">512</span>
    Lambda Timeout:       <span class="m">30</span>
    Lambda Runtime:       python3.6
    Lambda VPC ID:        None
    Invocations <span class="o">(</span>24h<span class="o">)</span>:    <span class="m">6</span>
    Errors <span class="o">(</span>24h<span class="o">)</span>:         <span class="m">0</span>
    Error Rate <span class="o">(</span>24h<span class="o">)</span>:     <span class="m">0</span>.00%
    API Gateway URL:      https://qdb669kwf9.execute-api.eu-central-1.amazonaws.com/dev
    Domain URL:           None Supplied
    Num. Event Rules:     <span class="m">1</span>
    Event Rule Name:      lambda-dev-zappa-keep-warm-handler.keep_warm_callback
    Event Rule Schedule:  rate<span class="o">(</span><span class="m">4</span> minutes<span class="o">)</span>
    Event Rule State:     Enabled
    Event Rule ARN:       arn:aws:events:eu-central-1:070741064749:rule/lambda-dev-zappa-keep-warm-handler.keep_warm_callback
</pre></div>


<p>The <code>API Gateway URL:</code> indicates the new home of your gun detection service.</p>
<h2>Confirm that the service is working</h2>
<p>Once the new Lambda service is up and running you can call it using curl like you did when testing locally, but exchanging the endpoint from <code>localhost:5000</code> to the API Gateway URL.</p>
<div class="highlight"><pre><span></span>curl -X POST -H <span class="s2">&quot;Content-Type: application/json&quot;</span> -d <span class="s1">&#39;{&quot;payload&quot;: [</span>
<span class="s1">    &quot;Trump Bannon row: White House lawyers threaten former aide&quot;,&quot;Caravan self-defence shotgun killer jailed for firearm possession&quot;</span>
<span class="s1">    ]}&#39;</span> https://qdk769zwf8.execute-api.eu-central-1.amazonaws.com/dev

<span class="o">{</span>
    <span class="s2">&quot;Caravan self-defence shotgun killer jailed for firearm possession&quot;</span>: <span class="m">0</span>.7338601611795328, 
    <span class="s2">&quot;Trump Bannon row: White House lawyers threaten former aide&quot;</span>: <span class="m">0</span>.14908094037784062
<span class="o">}</span>
</pre></div>


<p>If you prefer a graphical interface you could use <a href="https://www.getpostman.com/">Postman</a>. Provide the endpoint and payload as in the screenshot below, and you should receive a JSON document back with the scores if everything is working as intended.
<img alt="Testing the service with Postman" width="98%" src="/images/postman.png"/></p>
<h1>Why not use a web server?</h1>
<p>At this point you might wonder why we make all this effort to create a Lambda function to host the prediction service when you could host the Flask app on a traditional web server. For example, you could launch an AWS EC2 instance, run the Flask app on this instance, and configure the network to allow traffic to the app. </p>
<p>One reason is fault tolerance and availability. If the instance goes down for some reason, you would need to set up a health check to detect it, then automatically launch a new instance to host the Flask app. In addition to the extra work that means for yourself, the service would be unavailable for a minute or so while the new instance is powering up. Depending on the use case this can be a deal breaker.</p>
<p>A second reason is scalability. If the number of users increases you would need to make use of load balancers and launch copies of your instance through auto scaling groups to ensure that your instance is not over crowded. Likewise, you probably want to scale down the number of instances to save money when the load decreases.</p>
<p>The third reason is cost effectiveness. The first one million requests to AWS Lambda each month is free. The charges outside of this free tier are <a href="https://aws.amazon.com/lambda/pricing/">very affordable</a> and I struggle to find a scenario where a serverless architecture would be less cost effective than a solution with servers.</p>
<p>The downside I see with AWS Lambda is that it is hard to understand errors and perform bug fixing. For this reason, I find local testing to be vital to the data science life cycle. I used a t2 micro EC2 instance to test the prediction service used in this demo before deploying it as a serverless service.</p>
<h1>Summary</h1>
<p>If you followed all the steps you should now have a live web service that can score text documents depending on their likelihood to discuss weapons and firearms. </p>
<p>A software engineer can now be add this service as a component of a product. For example, you could add a frontend to provide the text input and return the scores, or you could integrate it with a program running locally. </p>
<p>The ability to deploy the prediction service independently of the training of the model, enables organizations to benefit from the high availability and low cost of a serverless solution while retaining full control of the data used in training the machine learning model.</p>
<p>Please let me know if you have comments or questions below.</p><p><a href="https://rsandstroem.github.io/serverlessPredictionService.html#disqus_thread">comments</a></p>                </article>
                <section>
                    <p id="post-share-links">
                    Share on:
                    <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A//rsandstroem.github.io/serverlessPredictionService.html&title=Hosting%20a%20machine%20learning%20prediction%20service%20on%20serverless%20infrastructure&summary=Learn%20how%20to%20host%20machine%20learning%20prediction%20services%20on%20the%20cloud%20with%20infinite%20scaling%2C%20zero%20downtime%2C%20zero%20maintenance%2C%20at%20a%20very%20low%20cost.&source=https%3A//rsandstroem.github.io/serverlessPredictionService.html" target="_blank" title="Share on LinkedIn">LinkedIn</a>
                    ❄
                    <a href="http://twitter.com/home?status=Hosting%20a%20machine%20learning%20prediction%20service%20on%20serverless%20infrastructure%20https%3A//rsandstroem.github.io/serverlessPredictionService.html" target="_blank" title="Share on Twitter">Twitter</a>
                    ❄
                    <a href="http://www.facebook.com/sharer/sharer.php?u=https%3A//rsandstroem.github.io/serverlessPredictionService.html" target="_blank" title="Share on Facebook">Facebook</a>
                    ❄
                    <a href="https://plus.google.com/share?url=https%3A//rsandstroem.github.io/serverlessPredictionService.html" target="_blank" title="Share on Google Plus">Google+</a>
                    ❄
                    <a href="mailto:?subject=Hosting%20a%20machine%20learning%20prediction%20service%20on%20serverless%20infrastructure&amp;body=https%3A//rsandstroem.github.io/serverlessPredictionService.html" target="_blank" title="Share via Email">Email</a>
                    </p>
                </section>
            </aside><!-- /#featured -->
                <section id="content" class="body">
                    <h1>Other articles</h1>
                    <ol id="posts-list" class="hfeed">

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/sparkdataframes.html" rel="bookmark"
                           title="Permalink to Data wrangling in Pandas and Spark - Time series of energy production">Data wrangling in Pandas and Spark - Time series of energy production</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Son 24 September 2017</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/spark.html">spark</a><a href="https://rsandstroem.github.io/tag/pandas.html">pandas</a><a href="https://rsandstroem.github.io/tag/python.html">python</a><a href="https://rsandstroem.github.io/tag/data-wrangling.html">data wrangling</a><a href="https://rsandstroem.github.io/tag/time-series.html">time series</a><a href="https://rsandstroem.github.io/tag/energy.html">energy</a><a href="https://rsandstroem.github.io/tag/tutorial.html">tutorial</a></span>
</footer><!-- /.post-info -->                
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>An important part of the everyday tasks of a data scientist is data wrangling. Input data must be accessed, retrieved, understood, and transformed before machine learning can be applied to create predictive models. While most talk is around deep learning these days, this less sexy topic is arguably more important for real life situations.</p>
                <a class="readmore" href="https://rsandstroem.github.io/sparkdataframes.html">read more</a>
<p><a href="https://rsandstroem.github.io/sparkdataframes.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/rpythonsastrendsdatascience.html" rel="bookmark"
                           title="Permalink to Which is the most popular language for data science in 2017?">Which is the most popular language for data science in 2017?</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Son 20 August 2017</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/r.html">r</a><a href="https://rsandstroem.github.io/tag/python.html">python</a><a href="https://rsandstroem.github.io/tag/sas.html">sas</a><a href="https://rsandstroem.github.io/tag/data-science.html">data science</a></span>
</footer><!-- /.post-info -->                
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Which is the most popular language for data science in 2017?</p>
<p>While performing a market analysis for a business case I looked at some trends in the field, and made a quick query to answer the above question "for fun". Since the result was both striking and rather unexpected I decided to share it with you in this blog post. (Plus, it gave me an excuse to add support for <a href="http://bokeh.pydata.org/en/latest/docs/reference.html">Bokeh</a>
                <a class="readmore" href="https://rsandstroem.github.io/rpythonsastrendsdatascience.html">read more</a>
<p><a href="https://rsandstroem.github.io/rpythonsastrendsdatascience.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/gpuDeepLearningWindows.html" rel="bookmark"
                           title="Permalink to GPU Accelerated Deep Learning on Windows">GPU Accelerated Deep Learning on Windows</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Mon 17 Juli 2017</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/gpu.html">gpu</a><a href="https://rsandstroem.github.io/tag/deep-learning.html">deep learning</a><a href="https://rsandstroem.github.io/tag/machine-learning.html">machine learning</a><a href="https://rsandstroem.github.io/tag/python.html">python</a><a href="https://rsandstroem.github.io/tag/installation.html">installation</a><a href="https://rsandstroem.github.io/tag/tutorial.html">tutorial</a></span>
</footer><!-- /.post-info -->                <p>The computers at my workplace are all running some version of Microsoft Windows. While that makes perfect sense in a Business Intelligence context, it unusual for a Data Science setup.</p>
                <a class="readmore" href="https://rsandstroem.github.io/gpuDeepLearningWindows.html">read more</a>
<p><a href="https://rsandstroem.github.io/gpuDeepLearningWindows.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/sparkkmeans.html" rel="bookmark"
                           title="Permalink to Running KMeans clustering on Spark">Running KMeans clustering on Spark</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Don 06 Juli 2017</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/spark.html">spark</a><a href="https://rsandstroem.github.io/tag/python.html">python</a><a href="https://rsandstroem.github.io/tag/kmeans.html">kmeans</a><a href="https://rsandstroem.github.io/tag/machine-learning.html">machine learning</a><a href="https://rsandstroem.github.io/tag/tutorial.html">tutorial</a></span>
</footer><!-- /.post-info -->                
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In a recent project I was facing the task of running machine learning on about 100 TB of data. This amount of data was exceeding the capacity of my workstation, so I translated the code from running on scikit-learn to Apache Spark using the PySpark API. This allowed me to process that data using in-memory distributed computing.</p>
                <a class="readmore" href="https://rsandstroem.github.io/sparkkmeans.html">read more</a>
<p><a href="https://rsandstroem.github.io/sparkkmeans.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/chatbotHosting.html" rel="bookmark"
                           title="Permalink to Building a chat bot - hosting">Building a chat bot - hosting</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Son 04 Juni 2017</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/chat-bot.html">chat bot</a><a href="https://rsandstroem.github.io/tag/azure.html">azure</a></span>
</footer><!-- /.post-info -->                <p>In conjunction with a public referendum I was given the task to create an intelligent chat bot. The chat bot could understand what the user wanted to know and provide the answers our subject matter experts had prepared. This post describes you can give users access to the bot by hosting it at a web service. It also describes how to add more developers to the project. The post assumes that you have already read the <a href="chatbotNLP.html">first post</a> and <a href="chatbotJS">second post</a> on this topic.</p>
                <a class="readmore" href="https://rsandstroem.github.io/chatbotHosting.html">read more</a>
<p><a href="https://rsandstroem.github.io/chatbotHosting.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/chatbotJS.html" rel="bookmark"
                           title="Permalink to Building a chat bot - programming">Building a chat bot - programming</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Son 30 April 2017</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/chat-bot.html">chat bot</a><a href="https://rsandstroem.github.io/tag/javascript.html">javascript</a><a href="https://rsandstroem.github.io/tag/nodejs.html">node.js</a><a href="https://rsandstroem.github.io/tag/azure-table-storage.html">azure table storage</a></span>
</footer><!-- /.post-info -->                <p>In conjunction with a public referendum I was given the task to create an intelligent chat bot. The chat bot could understand what the user wanted to know and provide the answers our subject matter experts had prepared. This post describes how to program the bot to capture user intents and take action. The post assumes that you have already read the <a href="chatbotNLP.html">first post on this topic</a>.</p>
                <a class="readmore" href="https://rsandstroem.github.io/chatbotJS.html">read more</a>
<p><a href="https://rsandstroem.github.io/chatbotJS.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/chatbotNLP.html" rel="bookmark"
                           title="Permalink to Building a chat bot - first steps">Building a chat bot - first steps</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Die 28 März 2017</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/chat-bot.html">chat bot</a><a href="https://rsandstroem.github.io/tag/natural-language-processing.html">natural language processing</a></span>
</footer><!-- /.post-info -->                <p>In conjunction with a public referendum I was given the task to create an intelligent chat bot. The chat bot could understand what the user wanted to know and provide the answers our subject matter experts had prepared. This post describes the first step of setting up such a chat bot.</p>
                <a class="readmore" href="https://rsandstroem.github.io/chatbotNLP.html">read more</a>
<p><a href="https://rsandstroem.github.io/chatbotNLP.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/discovery-of-the-higgs-boson.html" rel="bookmark"
                           title="Permalink to Discovery of the Higgs Boson">Discovery of the Higgs Boson</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Don 09 Februar 2017</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/higgs.html">higgs</a><a href="https://rsandstroem.github.io/tag/physics.html">physics</a><a href="https://rsandstroem.github.io/tag/announcement.html">announcement</a></span>
</footer><!-- /.post-info -->                This week I wanted to draw attention to the book that my former colleagues and I wrote, and which was recently published. It is great to finally have it in my hand! The book is about the discovery of the Higgs boson at the Large Hadron Collider at CERN.
                <a class="readmore" href="https://rsandstroem.github.io/discovery-of-the-higgs-boson.html">read more</a>
<p><a href="https://rsandstroem.github.io/discovery-of-the-higgs-boson.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/predicting-retail-sales.html" rel="bookmark"
                           title="Permalink to Predicting retail sales">Predicting retail sales</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Don 09 Februar 2017</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/python.html">python</a><a href="https://rsandstroem.github.io/tag/machine-learning.html">machine learning</a><a href="https://rsandstroem.github.io/tag/retail.html">retail</a><a href="https://rsandstroem.github.io/tag/time-series.html">time series</a><a href="https://rsandstroem.github.io/tag/tutorial.html">tutorial</a></span>
</footer><!-- /.post-info -->                Sometime you have a time series of historical data and you would like to know how this series of data will look in the days or years to come. If the data looks 
                <a class="readmore" href="https://rsandstroem.github.io/predicting-retail-sales.html">read more</a>
<p><a href="https://rsandstroem.github.io/predicting-retail-sales.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/building-a-data-lake-2-querying-json-from-hive.html" rel="bookmark"
                           title="Permalink to Building a data lake 2: Querying JSON from Hive">Building a data lake 2: Querying JSON from Hive</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Don 06 Oktober 2016</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/azure.html">azure</a><a href="https://rsandstroem.github.io/tag/hive.html">hive</a><a href="https://rsandstroem.github.io/tag/json.html">json</a><a href="https://rsandstroem.github.io/tag/tutorial.html">tutorial</a><a href="https://rsandstroem.github.io/tag/big-data.html">big data</a></span>
</footer><!-- /.post-info -->                Tutorial on creating Hive tables from JSON documents and joining the tables to create an enriched data set.
                <a class="readmore" href="https://rsandstroem.github.io/building-a-data-lake-2-querying-json-from-hive.html">read more</a>
<p><a href="https://rsandstroem.github.io/building-a-data-lake-2-querying-json-from-hive.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/installing-r-studio-on-azure-hdinsight.html" rel="bookmark"
                           title="Permalink to Installing R-studio on Azure HDInsight">Installing R-studio on Azure HDInsight</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Son 11 September 2016</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/azure.html">azure</a><a href="https://rsandstroem.github.io/tag/r.html">r</a><a href="https://rsandstroem.github.io/tag/tutorial.html">tutorial</a></span>
</footer><!-- /.post-info -->                Running R on Spark brings the advantage of distributed in memory computing and access to data stored in HDFS. In this context, it is convenient to have access to R-studio hosted from the R-server. In this post I will show a few ways how to install R-studio on the edge node of a HDInsight Spark cluster.
                <a class="readmore" href="https://rsandstroem.github.io/installing-r-studio-on-azure-hdinsight.html">read more</a>
<p><a href="https://rsandstroem.github.io/installing-r-studio-on-azure-hdinsight.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/create-azure-hdinsight-clusters-using-templates.html" rel="bookmark"
                           title="Permalink to Create Azure HDInsight clusters using templates">Create Azure HDInsight clusters using templates</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Don 01 September 2016</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/azure.html">azure</a><a href="https://rsandstroem.github.io/tag/cloud.html">cloud</a><a href="https://rsandstroem.github.io/tag/architecture.html">architecture</a><a href="https://rsandstroem.github.io/tag/tutorial.html">tutorial</a><a href="https://rsandstroem.github.io/tag/big-data.html">big data</a></span>
</footer><!-- /.post-info -->                Microsoft Azure provides big data infrastructure through the HDInsight product. However, they bill you per hour, no matter if you use the computing resources or not. One option is to destroy clusters when they are not needed, but to get the clusters back up with minimum effort it is best to use predefined scripts or templates. This post shows you a few alternatives how to accomplish this.
                <a class="readmore" href="https://rsandstroem.github.io/create-azure-hdinsight-clusters-using-templates.html">read more</a>
<p><a href="https://rsandstroem.github.io/create-azure-hdinsight-clusters-using-templates.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/can-you-trust-your-data.html" rel="bookmark"
                           title="Permalink to Can you trust your data?">Can you trust your data?</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Son 28 August 2016</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/business.html">business</a><a href="https://rsandstroem.github.io/tag/statistics.html">statistics</a><a href="https://rsandstroem.github.io/tag/perspective.html">perspective</a></span>
</footer><!-- /.post-info -->                Business is the process of managing under conditions of uncertainty. To ensure optimal outcome business leaders must base their decisions on information of varying reliability. This is not new, humans always had a need for making decisions with uncertain outcomes. “Is he a friend or foe?” “Should I trade my food for a hammer?” “Can I reach safety if I turn and run, or should I fight the lion?”
                <a class="readmore" href="https://rsandstroem.github.io/can-you-trust-your-data.html">read more</a>
<p><a href="https://rsandstroem.github.io/can-you-trust-your-data.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/impact-of-big-data-on-the-insurance-industry.html" rel="bookmark"
                           title="Permalink to Impact of Big Data on the Insurance Industry">Impact of Big Data on the Insurance Industry</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Son 28 August 2016</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/business.html">business</a><a href="https://rsandstroem.github.io/tag/big-data.html">big data</a><a href="https://rsandstroem.github.io/tag/insurance.html">insurance</a><a href="https://rsandstroem.github.io/tag/perspective.html">perspective</a></span>
</footer><!-- /.post-info -->                Big Data is bringing decisive advantages to insurers through more relevant, detailed, and up to date information than was previously possible. At the center of this transformation are customers. They expect to be able to select products defined and driven by their needs, preferences and convenience.
                <a class="readmore" href="https://rsandstroem.github.io/impact-of-big-data-on-the-insurance-industry.html">read more</a>
<p><a href="https://rsandstroem.github.io/impact-of-big-data-on-the-insurance-industry.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/building-a-data-lake-1-weather-and-time.html" rel="bookmark"
                           title="Permalink to Building a data lake 1: Weather and time">Building a data lake 1: Weather and time</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Sam 20 August 2016</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/python.html">python</a><a href="https://rsandstroem.github.io/tag/api.html">api</a><a href="https://rsandstroem.github.io/tag/time-series.html">time series</a><a href="https://rsandstroem.github.io/tag/tutorial.html">tutorial</a></span>
</footer><!-- /.post-info -->                I am currently building a data lake which will be used to improve operations at an energy company using machine learning. Among the many interesting topics the following are prioritized:

    Can we predict the energy production of hydroelectric, solar and wind power plants?
    Can we predict the energy consumption using weather reports? After all, home owners need to heat their homes more on a cold winter day than on a sunny day in October.
                <a class="readmore" href="https://rsandstroem.github.io/building-a-data-lake-1-weather-and-time.html">read more</a>
<p><a href="https://rsandstroem.github.io/building-a-data-lake-1-weather-and-time.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/GeoMapsFoliumDemo.html" rel="bookmark"
                           title="Permalink to Using Folium to show geographic data">Using Folium to show geographic data</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Son 14 August 2016</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/python.html">python</a><a href="https://rsandstroem.github.io/tag/folium.html">folium</a><a href="https://rsandstroem.github.io/tag/geo.html">geo</a><a href="https://rsandstroem.github.io/tag/tutorial.html">tutorial</a></span>
</footer><!-- /.post-info -->                
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This post demonstrates how to</p>
<ul>
<li>Display a map from OpenStreetMaps using Folium</li>
<li>Add custom shape files to define regions of interest</li>
<li>Color the regions of interest based on data in a pandas dataframe</li>
<li>(New) Brief introduction to GeoPandas.</li>
</ul>
<p>The code of this post is available at <a href="https://github.com/rsandstroem/IPythonNotebooks/blob/master/GeoMapsFoliumDemo/GeoMapsFoliumDemo.ipynb">https://github.com/rsandstroem/IPythonNotebooks/blob/master/GeoMapsFoliumDemo/GeoMapsFoliumDemo.ipynb</a> .</p>
<p><em>August 1, 2017: This post is almost a year old, but I decided to make some technical improvements to it to improve the viewing experience online. (It is the Swiss National Day after all!) During this renovation, I stumbled upon GeoPandas, which is a great package worth mentioning in this context.</em>
                <a class="readmore" href="https://rsandstroem.github.io/GeoMapsFoliumDemo.html">read more</a>
<p><a href="https://rsandstroem.github.io/GeoMapsFoliumDemo.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="https://rsandstroem.github.io/MongoDBDemo.html" rel="bookmark"
                           title="Permalink to Simple MongoDB demo">Simple MongoDB demo</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <span>Son 14 August 2016</span>
<span>| tags: <a href="https://rsandstroem.github.io/tag/python.html">python</a><a href="https://rsandstroem.github.io/tag/mongodb.html">mongodb</a><a href="https://rsandstroem.github.io/tag/tutorial.html">tutorial</a></span>
</footer><!-- /.post-info -->                
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">Introduction<a class="anchor-link" href="#Introduction"></a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This blog post is a tutorial that introduces the basics of MongoDB and how to utilize it within a python environment. To accomplish this we will use pymongo to connect python with MongoDB.</p>
<p>Mongo DB is a convenient NoSQL database which uses JSON syntax to store and query documents. I am frequently using MongoDB when dealing with streaming data from sensors or APIs. In big data scenarios I find MongoDB powerful since it allows for replication and sharding, thus enabling distributed computing and high availability, but that is a topic for another tutorial!</p>
                <a class="readmore" href="https://rsandstroem.github.io/MongoDBDemo.html">read more</a>
<p><a href="https://rsandstroem.github.io/MongoDBDemo.html#disqus_thread">comments</a></p>                </div><!-- /.entry-content -->
            </article></li>
            </ol><!-- /#posts-list -->
            </section><!-- /#content -->
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>blogroll</h2>
                        <ul>
                            <li><a href="http://getpelican.com/">Pelican</a></li>
                            <li><a href="http://python.org/">Python.org</a></li>
                            <li><a href="http://jinja.pocoo.org/">Jinja2</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="https://ch.linkedin.com/in/rikard-sandström-a0b3229">LinkedIn</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <p>Powered by <a href="http://getpelican.com/">Pelican</a>. Theme <a href="https://github.com/blueicefield/pelican-blueidea/">blueidea</a>, inspired by the default theme.</p>
        </footer><!-- /#contentinfo -->

    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-83199770-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
<script type="text/javascript">
    var disqus_shortname = 'data-scientist-blog';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>
</html>